{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "test_entity_ids_file = 'entity_ids.txt'\n",
    "test_read_count_paths_file = 'read_count_paths.txt'\n",
    "test_clustering_table_file = 'clustering_table.tsv'\n",
    "test_training_blacklist_file = 'training_blacklist.txt'\n",
    "\n",
    "test_num_samples = 10000\n",
    "test_entity_ids = np.array(['sample_{:d}'.format(i) \n",
    "                            for i in range(1, test_num_samples + 1)])\n",
    "np.savetxt(test_entity_ids_file, test_entity_ids, fmt='%s')\n",
    "\n",
    "test_read_count_paths = ['gs://fake-bucket/sample_{:d}.counts.tsv'.format(i) \n",
    "                         for i in range(1, test_num_samples + 1)]\n",
    "np.savetxt(test_read_count_paths_file, test_read_count_paths, fmt='%s')\n",
    "\n",
    "test_num_clusters = 30\n",
    "test_dirichlet_alpha = 0.001\n",
    "test_around_num_digits = 3\n",
    "test_cluster_names = ['CLUSTER_{:d}'.format(i) \n",
    "                      for i in range(1, test_num_clusters + 1)]\n",
    "test_clustering_df = pd.DataFrame(columns=['SAMPLE_NAME'] + test_cluster_names)\n",
    "test_unnorm_responsibilities = np.around(np.random.dirichlet(test_dirichlet_alpha * np.ones(test_num_clusters), \n",
    "                                                             size=test_num_samples), \n",
    "                                         test_around_num_digits)\n",
    "test_responsibilities = test_unnorm_responsibilities / np.sum(test_unnorm_responsibilities, axis=1)[:, np.newaxis]\n",
    "test_clustering_df['SAMPLE_NAME'] = test_entity_ids\n",
    "test_clustering_df[test_cluster_names] = test_responsibilities\n",
    "test_clustering_df.to_csv(test_clustering_table_file, sep='\\t', index=False)\n",
    "\n",
    "test_training_blacklist_fraction = 0.02\n",
    "test_training_blacklist = test_entity_ids[1 == np.random.choice([0, 1], \n",
    "                                                                p=[1 - test_training_blacklist_fraction, test_training_blacklist_fraction], \n",
    "                                                                size=test_num_samples)]\n",
    "np.savetxt(test_training_blacklist_file, test_training_blacklist, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_cohorts_and_cases_and_write_results(output_dir: str,\n",
    "                                                  entity_ids_file: List[str],\n",
    "                                                  read_count_paths_file: List[str],\n",
    "                                                  clustering_table_file: str, \n",
    "                                                  training_blacklist_file: str,\n",
    "                                                  number_of_training_samples_per_model: int):\n",
    "    #load all files\n",
    "    entity_ids = np.loadtxt(entity_ids_file, dtype=str)\n",
    "    read_count_paths = np.loadtxt(read_count_paths_file, dtype=str)\n",
    "    assert len(entity_ids) == len(read_count_paths), \\\n",
    "        \"Number of entity IDs and number of read count paths must be equal.\"\n",
    "    clustering_table_df = pd.read_csv(clustering_table_file, sep='\\t')\n",
    "    cluster_names = clustering_table_df.columns[1:]\n",
    "    training_blacklist = np.loadtxt(training_blacklist_file, dtype=str)\n",
    "    \n",
    "    results_df = pd.DataFrame(columns=['SAMPLE_NAME', \n",
    "                                       'READ_COUNT_PATH', \n",
    "                                       'CLUSTER_MEMBERSHIP', \n",
    "                                       'IN_TRAINING_BLACKLIST', \n",
    "                                       'IN_RESCUE_LIST', \n",
    "                                       'TRAINING_SAMPLE'])\n",
    "    \n",
    "    results_df['SAMPLE_NAME'] = entity_ids\n",
    "    results_df['READ_COUNT_PATH'] = read_count_paths\n",
    "    results_df['CLUSTER_MEMBERSHIP'] = clustering_table_df[cluster_names].idxmax(axis=1) # use MAP responsibility\n",
    "    results_df['IN_TRAINING_BLACKLIST'] = results_df['SAMPLE_NAME'].isin(training_blacklist)\n",
    "    number_of_blacklisted_samples_per_cluster = results_df.groupby('CLUSTER_MEMBERSHIP')['IN_TRAINING_BLACKLIST'].sum()\n",
    "    number_of_available_samples_per_cluster = results_df['CLUSTER_MEMBERSHIP'].value_counts() - number_of_blacklisted_samples_per_cluster\n",
    "    rescue_clusters = number_of_available_samples_per_cluster[number_of_available_samples_per_cluster < number_of_training_samples_per_model].keys()\n",
    "    results_df['IN_RESCUE_LIST'] = results_df['CLUSTER_MEMBERSHIP'].isin(rescue_clusters)\n",
    "    \n",
    "    training_samples = results_df[~results_df['IN_TRAINING_BLACKLIST'] & ~results_df['IN_RESCUE_LIST']] \\\n",
    "                                 .groupby('CLUSTER_MEMBERSHIP') \\\n",
    "                                 .apply(lambda x: x.sample(number_of_training_samples_per_model))['SAMPLE_NAME']\n",
    "            \n",
    "    results_df['TRAINING_SAMPLE'] = results_df['SAMPLE_NAME'].isin(training_samples)\n",
    "    \n",
    "    assert not any(results_df['IN_TRAINING_BLACKLIST'] & results_df['TRAINING_SAMPLE'])\n",
    "    assert not any(results_df['IN_RESCUE_LIST'] & results_df['TRAINING_SAMPLE'])\n",
    "    \n",
    "    print(results_df)\n",
    "    #output complete table\n",
    "    \n",
    "    #output entity id and read count path files for both training and case samples for each cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SAMPLE_NAME                           READ_COUNT_PATH  \\\n",
      "0         sample_1      gs://fake-bucket/sample_1.counts.tsv   \n",
      "1         sample_2      gs://fake-bucket/sample_2.counts.tsv   \n",
      "2         sample_3      gs://fake-bucket/sample_3.counts.tsv   \n",
      "3         sample_4      gs://fake-bucket/sample_4.counts.tsv   \n",
      "4         sample_5      gs://fake-bucket/sample_5.counts.tsv   \n",
      "5         sample_6      gs://fake-bucket/sample_6.counts.tsv   \n",
      "6         sample_7      gs://fake-bucket/sample_7.counts.tsv   \n",
      "7         sample_8      gs://fake-bucket/sample_8.counts.tsv   \n",
      "8         sample_9      gs://fake-bucket/sample_9.counts.tsv   \n",
      "9        sample_10     gs://fake-bucket/sample_10.counts.tsv   \n",
      "10       sample_11     gs://fake-bucket/sample_11.counts.tsv   \n",
      "11       sample_12     gs://fake-bucket/sample_12.counts.tsv   \n",
      "12       sample_13     gs://fake-bucket/sample_13.counts.tsv   \n",
      "13       sample_14     gs://fake-bucket/sample_14.counts.tsv   \n",
      "14       sample_15     gs://fake-bucket/sample_15.counts.tsv   \n",
      "15       sample_16     gs://fake-bucket/sample_16.counts.tsv   \n",
      "16       sample_17     gs://fake-bucket/sample_17.counts.tsv   \n",
      "17       sample_18     gs://fake-bucket/sample_18.counts.tsv   \n",
      "18       sample_19     gs://fake-bucket/sample_19.counts.tsv   \n",
      "19       sample_20     gs://fake-bucket/sample_20.counts.tsv   \n",
      "20       sample_21     gs://fake-bucket/sample_21.counts.tsv   \n",
      "21       sample_22     gs://fake-bucket/sample_22.counts.tsv   \n",
      "22       sample_23     gs://fake-bucket/sample_23.counts.tsv   \n",
      "23       sample_24     gs://fake-bucket/sample_24.counts.tsv   \n",
      "24       sample_25     gs://fake-bucket/sample_25.counts.tsv   \n",
      "25       sample_26     gs://fake-bucket/sample_26.counts.tsv   \n",
      "26       sample_27     gs://fake-bucket/sample_27.counts.tsv   \n",
      "27       sample_28     gs://fake-bucket/sample_28.counts.tsv   \n",
      "28       sample_29     gs://fake-bucket/sample_29.counts.tsv   \n",
      "29       sample_30     gs://fake-bucket/sample_30.counts.tsv   \n",
      "...            ...                                       ...   \n",
      "9970   sample_9971   gs://fake-bucket/sample_9971.counts.tsv   \n",
      "9971   sample_9972   gs://fake-bucket/sample_9972.counts.tsv   \n",
      "9972   sample_9973   gs://fake-bucket/sample_9973.counts.tsv   \n",
      "9973   sample_9974   gs://fake-bucket/sample_9974.counts.tsv   \n",
      "9974   sample_9975   gs://fake-bucket/sample_9975.counts.tsv   \n",
      "9975   sample_9976   gs://fake-bucket/sample_9976.counts.tsv   \n",
      "9976   sample_9977   gs://fake-bucket/sample_9977.counts.tsv   \n",
      "9977   sample_9978   gs://fake-bucket/sample_9978.counts.tsv   \n",
      "9978   sample_9979   gs://fake-bucket/sample_9979.counts.tsv   \n",
      "9979   sample_9980   gs://fake-bucket/sample_9980.counts.tsv   \n",
      "9980   sample_9981   gs://fake-bucket/sample_9981.counts.tsv   \n",
      "9981   sample_9982   gs://fake-bucket/sample_9982.counts.tsv   \n",
      "9982   sample_9983   gs://fake-bucket/sample_9983.counts.tsv   \n",
      "9983   sample_9984   gs://fake-bucket/sample_9984.counts.tsv   \n",
      "9984   sample_9985   gs://fake-bucket/sample_9985.counts.tsv   \n",
      "9985   sample_9986   gs://fake-bucket/sample_9986.counts.tsv   \n",
      "9986   sample_9987   gs://fake-bucket/sample_9987.counts.tsv   \n",
      "9987   sample_9988   gs://fake-bucket/sample_9988.counts.tsv   \n",
      "9988   sample_9989   gs://fake-bucket/sample_9989.counts.tsv   \n",
      "9989   sample_9990   gs://fake-bucket/sample_9990.counts.tsv   \n",
      "9990   sample_9991   gs://fake-bucket/sample_9991.counts.tsv   \n",
      "9991   sample_9992   gs://fake-bucket/sample_9992.counts.tsv   \n",
      "9992   sample_9993   gs://fake-bucket/sample_9993.counts.tsv   \n",
      "9993   sample_9994   gs://fake-bucket/sample_9994.counts.tsv   \n",
      "9994   sample_9995   gs://fake-bucket/sample_9995.counts.tsv   \n",
      "9995   sample_9996   gs://fake-bucket/sample_9996.counts.tsv   \n",
      "9996   sample_9997   gs://fake-bucket/sample_9997.counts.tsv   \n",
      "9997   sample_9998   gs://fake-bucket/sample_9998.counts.tsv   \n",
      "9998   sample_9999   gs://fake-bucket/sample_9999.counts.tsv   \n",
      "9999  sample_10000  gs://fake-bucket/sample_10000.counts.tsv   \n",
      "\n",
      "     CLUSTER_MEMBERSHIP  IN_TRAINING_BLACKLIST  IN_RESCUE_LIST  \\\n",
      "0            CLUSTER_27                  False           False   \n",
      "1             CLUSTER_7                  False           False   \n",
      "2            CLUSTER_23                  False            True   \n",
      "3            CLUSTER_16                   True           False   \n",
      "4            CLUSTER_24                  False           False   \n",
      "5             CLUSTER_1                  False           False   \n",
      "6            CLUSTER_12                  False           False   \n",
      "7            CLUSTER_30                  False            True   \n",
      "8             CLUSTER_5                  False           False   \n",
      "9            CLUSTER_12                  False           False   \n",
      "10           CLUSTER_22                  False           False   \n",
      "11           CLUSTER_15                  False           False   \n",
      "12           CLUSTER_24                  False           False   \n",
      "13            CLUSTER_8                  False           False   \n",
      "14           CLUSTER_11                  False           False   \n",
      "15            CLUSTER_7                  False           False   \n",
      "16            CLUSTER_7                  False           False   \n",
      "17            CLUSTER_4                  False           False   \n",
      "18           CLUSTER_23                  False            True   \n",
      "19           CLUSTER_17                  False           False   \n",
      "20           CLUSTER_11                  False           False   \n",
      "21           CLUSTER_19                  False           False   \n",
      "22            CLUSTER_6                  False           False   \n",
      "23           CLUSTER_12                  False           False   \n",
      "24           CLUSTER_10                  False           False   \n",
      "25            CLUSTER_4                  False           False   \n",
      "26           CLUSTER_21                  False           False   \n",
      "27            CLUSTER_2                  False            True   \n",
      "28            CLUSTER_4                  False           False   \n",
      "29           CLUSTER_20                  False           False   \n",
      "...                 ...                    ...             ...   \n",
      "9970         CLUSTER_25                  False           False   \n",
      "9971         CLUSTER_25                  False           False   \n",
      "9972         CLUSTER_18                  False           False   \n",
      "9973         CLUSTER_23                  False            True   \n",
      "9974         CLUSTER_23                  False            True   \n",
      "9975         CLUSTER_13                  False           False   \n",
      "9976         CLUSTER_16                  False           False   \n",
      "9977         CLUSTER_14                  False           False   \n",
      "9978          CLUSTER_1                  False           False   \n",
      "9979          CLUSTER_2                  False            True   \n",
      "9980         CLUSTER_11                  False           False   \n",
      "9981         CLUSTER_26                  False           False   \n",
      "9982         CLUSTER_25                  False           False   \n",
      "9983         CLUSTER_27                  False           False   \n",
      "9984          CLUSTER_3                  False           False   \n",
      "9985         CLUSTER_10                  False           False   \n",
      "9986         CLUSTER_21                  False           False   \n",
      "9987         CLUSTER_30                  False            True   \n",
      "9988         CLUSTER_23                  False            True   \n",
      "9989          CLUSTER_1                  False           False   \n",
      "9990         CLUSTER_30                  False            True   \n",
      "9991         CLUSTER_24                  False           False   \n",
      "9992         CLUSTER_17                  False           False   \n",
      "9993         CLUSTER_12                  False           False   \n",
      "9994         CLUSTER_15                  False           False   \n",
      "9995         CLUSTER_18                  False           False   \n",
      "9996         CLUSTER_21                  False           False   \n",
      "9997         CLUSTER_16                  False           False   \n",
      "9998         CLUSTER_20                  False           False   \n",
      "9999         CLUSTER_18                  False           False   \n",
      "\n",
      "      TRAINING_SAMPLE  \n",
      "0                True  \n",
      "1                True  \n",
      "2               False  \n",
      "3               False  \n",
      "4                True  \n",
      "5                True  \n",
      "6                True  \n",
      "7               False  \n",
      "8                True  \n",
      "9                True  \n",
      "10               True  \n",
      "11              False  \n",
      "12               True  \n",
      "13               True  \n",
      "14              False  \n",
      "15               True  \n",
      "16               True  \n",
      "17               True  \n",
      "18              False  \n",
      "19               True  \n",
      "20               True  \n",
      "21               True  \n",
      "22               True  \n",
      "23               True  \n",
      "24               True  \n",
      "25               True  \n",
      "26               True  \n",
      "27              False  \n",
      "28               True  \n",
      "29               True  \n",
      "...               ...  \n",
      "9970             True  \n",
      "9971             True  \n",
      "9972             True  \n",
      "9973            False  \n",
      "9974            False  \n",
      "9975             True  \n",
      "9976             True  \n",
      "9977             True  \n",
      "9978             True  \n",
      "9979            False  \n",
      "9980             True  \n",
      "9981             True  \n",
      "9982             True  \n",
      "9983             True  \n",
      "9984            False  \n",
      "9985             True  \n",
      "9986            False  \n",
      "9987            False  \n",
      "9988            False  \n",
      "9989             True  \n",
      "9990            False  \n",
      "9991             True  \n",
      "9992             True  \n",
      "9993             True  \n",
      "9994            False  \n",
      "9995             True  \n",
      "9996             True  \n",
      "9997             True  \n",
      "9998             True  \n",
      "9999             True  \n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "output_dir = '.'\n",
    "number_of_training_samples_per_model = 300\n",
    "\n",
    "determine_cohorts_and_cases_and_write_results(output_dir,\n",
    "                                              test_entity_ids_file,\n",
    "                                              test_read_count_paths_file,\n",
    "                                              test_clustering_table_file, \n",
    "                                              test_training_blacklist_file,\n",
    "                                              number_of_training_samples_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--output_dir OUTPUT_DIR]\n",
      "                             [--entity_ids ENTITY_IDS [ENTITY_IDS ...]]\n",
      "                             [--read_count_files READ_COUNT_FILES [READ_COUNT_FILES ...]]\n",
      "                             [--clustering_table_file CLUSTERING_TABLE_FILE]\n",
      "                             [--training_blacklist_file TRAINING_BLACKLIST_FILE]\n",
      "                             [--number_of_training_samples_per_model NUMBER_OF_TRAINING_SAMPLES_PER_MODEL]\n",
      "                             [--minimum_number_of_samples_per_cluster MINIMUM_NUMBER_OF_SAMPLES_PER_CLUSTER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1890032050/jupyter/kernel-8383480e-4347-4106-809e-38fa9d8a48ad.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/BROAD.MIT.EDU/slee/.pyenv/versions/anaconda3-4.3.1/envs/gatk-ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--output_dir', \n",
    "                        type=str,    \n",
    "                        help='Output directory')\n",
    "    \n",
    "    parser.add_argument('--entity_ids_file', \n",
    "                        type=str,\n",
    "                        help='File containing entity IDs corresponding to read count paths')\n",
    "    \n",
    "    parser.add_argument('--read_count_paths_file', \n",
    "                        type=str,\n",
    "                        help='File containing read count paths (output of GATK CollectReadCounts) corresponding to entity IDs')\n",
    "\n",
    "    parser.add_argument('--clustering_table_file',\n",
    "                        type=str,\n",
    "                        help='Table of clustered samples (output of ClusterSamplesFromCoverage workflow)')\n",
    "    \n",
    "    parser.add_argument('--training_blacklist_file',\n",
    "                        type=str,\n",
    "                        help='File containing blacklist of entity IDs for samples not to be used for training models')\n",
    "    \n",
    "    parser.add_argument('--number_of_training_samples_per_model',\n",
    "                        type=int,\n",
    "                        help='Number of samples used to train each model; samples in clusters with a number of ' +\n",
    "                             'non-blacklisted samples less than this will be output to a rescue list')\n",
    "\n",
    "    args = parser.parse_args()\n",
    " \n",
    "    output_dir = args.output_dir\n",
    "    entity_ids_file = args.entity_ids_file\n",
    "    read_count_paths_file = args.read_count_paths_file\n",
    "    clustering_table_file = args.clustering_table_file\n",
    "    training_blacklist_file = args.training_blacklist_file\n",
    "    number_of_training_samples_per_model = args.number_of_training_samples_per_model\n",
    "    \n",
    "    assert number_of_training_samples_per_model > 0, \"Number of training samples per model must be positive.\"\n",
    "\n",
    "    determine_cohorts_and_cases_and_write_results(output_dir,\n",
    "                                                  entity_ids_file,\n",
    "                                                  read_count_paths_file,\n",
    "                                                  clustering_table_file, \n",
    "                                                  training_blacklist_file,\n",
    "                                                  number_of_training_samples_per_model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
